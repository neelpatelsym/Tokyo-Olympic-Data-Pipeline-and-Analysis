{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7b10b32-eb29-434b-ac46-256e6b0e72fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count,col,when,isnan,row_number,date_format,from_utc_timestamp\n",
    "from pyspark.sql.types import TimestampType\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7dfd2db6-df81-4d3c-a77f-06816129c8e5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "input_path = '/mnt/tokyo_olympic/Silver-Layer/' # Path to silver layer in medallion architecture\n",
    "file_names = dbutils.fs.ls(input_path) \n",
    "dfs = {} # Creating dictionary to hold dataframes from silver layer \n",
    "Gold_dfs = {} # Creating dictionary to load transformed dataframes to gold layer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bb310f9-60cd-4807-9467-d5977f770f6f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Loading files in silver layer to dataframes in dictionary object dfs\n",
    "for file_name in file_names:\n",
    "    var = file_name.name.split('.')[0]\n",
    "    dfs[var[:-8:]] = spark.read.format('csv').option(\"header\",\"true\").option(\"InferSchema\",\"true\").load(file_name.path + var[:-8:] + '.csv/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b22c9bf-17c4-41ed-bbb1-f547a0b5bc58",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The files imported from silver layer are : dict_keys(['athlete_event', 'athletes', 'coaches', 'countries_medal_fact', 'countries', 'discipline_gender_fact', 'discipline', 'event', 'medals_fact', 'teams'])\n"
     ]
    }
   ],
   "source": [
    "print(f\"The files imported from silver layer are : {dfs.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fd16a3d-4f9d-4dbf-af29-06e3a8157d9d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Creating temp view for all imported silver layer dataframes\n",
    "for df_name,df_value in dfs.items():\n",
    "    dfs[df_name].createOrReplaceTempView(df_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "614eab69-e98b-4852-b876-3a2c7f8bae41",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Defining business logic to create Athletes Gold Dataframe\n",
    "Gold_dfs['athletes'] = spark.sql(\"Select a.Athlete_SID,a.Athlete_Name,a.Age,a.Gender,b.Country_SID,c.Discipline_SID from \\\n",
    "                           athletes a left join countries b on a.Country = b.Country\\\n",
    "                            left join discipline c on a.Discipline = c.Discipline\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be95375a-ab98-419f-a6ac-c9a365be4895",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating Countries Gold Dataframe\n",
    "Gold_dfs['countries'] = dfs['countries'].select(\"Country_SID\",\"Country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ece97290-4ea8-4cf6-926e-fe863916e7ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating coaches Gold Dataframe \n",
    "Gold_dfs['coaches'] = spark.sql(\"Select a.Coach_SID,a.Coach_Name, b.Country_SID,c.Discipline_SID from \\\n",
    "                           coaches a left join countries b on a.Country = b.Country\\\n",
    "                            left join discipline c on a.Discipline = c.Discipline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b4276ff-b9a9-49aa-82e5-c89b9a946281",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating discipline gender fact Gold Dataframe\n",
    "Gold_dfs['discipline_gender_fact'] = dfs['discipline_gender_fact'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cb7bdad-58c1-4e84-913d-e8181fdb4231",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Creating discipline Gold Dataframe\n",
    "Gold_dfs['discipline'] = dfs['discipline'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e07b41d-5b86-4b32-bf01-95061a8ca675",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Creating event Gold Dataframe\n",
    "Gold_dfs['event'] = dfs['event']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc0251ce-0d69-43ca-a947-511cd53ee742",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating medal countries fact Gold Dataframe\n",
    "Gold_dfs['countries_medal_fact'] = spark.sql(\"Select b.Country_SID,a.* except(Country) from \\\n",
    "                                     countries_medal_fact a left join countries b on a.Country = b.Country\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39e848f4-451b-4818-87ba-9a335538d249",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating medals fact Gold Dataframe\n",
    "Gold_dfs['medals_fact'] = spark.sql(\"Select a.Medals_Fact_SID,a.Medal_Date, b.Athlete_SID,c.Event_SID,\\\n",
    "                              a.Gold_Medals, a.Silver_Medals, a.Bronze_Medals from medals_fact a\\\n",
    "                              join athletes b on (a.Athlete_Name = b.Athlete_Name and a.Country = b.Country and a.Discipline = b.Discipline)\\\n",
    "                              join event c on a.Event = c.Event\\\n",
    "                              order by a.Medals_Fact_SID\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a11139e-9b29-4cb0-82aa-6f54fd70fdc0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating teams Gold Dataframe\n",
    "Gold_dfs['teams'] = spark.sql(\"Select a.Team_SID,a.Team_Name, b.Discipline_SID,c.Country_SID,d.Event_SID \\\n",
    "                       from teams a left join discipline b on a.Discipline = b.Discipline\\\n",
    "                                    left join countries c on a.Country = c.Country\\\n",
    "                                    left join event d on a.Event = d.Event\\\n",
    "                                    order by a.Team_SID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe5ed7e5-c4cb-4e06-b8bd-f96e54d9df54",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading transformed Dataframes in Gold Layer : dict_keys(['athletes', 'countries', 'coaches', 'discipline_gender_fact', 'discipline', 'event', 'countries_medal_fact', 'medals_fact', 'teams'])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading transformed Dataframes in Gold Layer : {Gold_dfs.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52732fc6-8e55-4800-af5c-c0e0f31d4b48",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Loading dataframes into Gold Layer:\n",
    "for df_name,df_value in Gold_dfs.items():\n",
    "    temp_output_path = '/mnt/tokyo_olympic/Gold-Layer/' + df_name + '/' + df_name + '_gold/'\n",
    "    output_path = '/mnt/tokyo_olympic/Gold-Layer/' + df_name '/' + df_name + '.parquet'\n",
    "    df_value.repartition(1).write.mode(\"overwrite\").option(\"header\",\"true\").csv(temp_output_path)\n",
    "    filenames = dbutils.fs.ls(temp_output_path)\n",
    "    for filename in filenames:\n",
    "        if filename.name.endswith('.parquet'):\n",
    "            name = filename.name\n",
    "    dbutils.fs.cp(temp_output_path + name, output_path)\n",
    "    dbutils.fs.rm(temp_output_path,recurse=True)\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Silver to Gold Notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
